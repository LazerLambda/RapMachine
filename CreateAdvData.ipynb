{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/home/philko/.cache/huggingface/datasets/wikitext/wikitext-103-raw-v1/1.0.0/47c57a6745aa5ce8e16a5355aaa4039e3aa90d1adad87cef1ad4e0f29e74ac91)\n",
      "Reusing dataset cnn_dailymail (/home/philko/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602)\n",
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (/home/philko/.cache/huggingface/datasets/tweets_hate_speech_detection/default/0.0.0/c32a982d8b2d6233065d820ac655454174f8aaa8faddc74979cf793486acd3b0)\n"
     ]
    }
   ],
   "source": [
    "dataset_wiki = load_dataset(\"wikitext\", 'wikitext-103-raw-v1')\n",
    "dataset_cnn = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
    "dataset_tweet = load_dataset(\"tweets_hate_speech_detection\")\n",
    "\n",
    "datasets: list = dataset_cnn['train']['article'] + dataset_wiki['test']['text'] + dataset_tweet['train']['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_raps: pd.DataFrame = pd.DataFrame.from_dict({'text': datasets, 'n': list(map(lambda e: len(e) if len(e) > 150 else None, datasets))})\n",
    "non_raps = non_raps.dropna()\n",
    "del datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load lyrics (pd.DataFrame with one lyrics-column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raps: pd.DataFrame = pd.read_json('Lyrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raps = raps.rename(columns={'lyrics':'text'})\n",
    "raps['n'] = raps['text'].apply(lambda row: len(row) if len(row) > 150 else None)\n",
    "raps = raps.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing character length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2662.064718162839"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(raps['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4012.397370452021"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(non_raps['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both datasets are unequal with respect to text length, the non-rap dataset must be truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288947, 210380)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raps_max = max(raps['n'])\n",
    "non_raps_clipped = non_raps[non_raps['n'] <= raps_max]\n",
    "len(non_raps), len(non_raps_clipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create similar dataset (considering length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.25 * len(raps))\n",
    "frst_qu = np.percentile(raps['n'], 25)\n",
    "scnd_qu = np.percentile(raps['n'], 50)\n",
    "thrd_qu = np.percentile(raps['n'], 75)\n",
    "frth_qu = raps_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample from quantiles to obtain a similar distributed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_data = pd.concat([non_raps_clipped[non_raps_clipped['n'] < frst_qu].sample(n=n),\n",
    "    non_raps_clipped[(non_raps_clipped['n'] < scnd_qu) & (non_raps_clipped['n'] >+ frst_qu)].sample(n=n),\n",
    "    non_raps_clipped[(non_raps_clipped['n'] < thrd_qu) & (non_raps_clipped['n'] >+ scnd_qu)].sample(n=n),\n",
    "    non_raps_clipped[(non_raps_clipped['n'] < frth_qu) & (non_raps_clipped['n'] >+ thrd_qu)].sample(n=n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_data['label'] = [0] * len(adv_data)\n",
    "raps['label'] = [1] * len(raps)\n",
    "data: pd.DataFrame = pd.concat([adv_data, raps])\n",
    "data = data.sample(n=len(data), ignore_index=True)\n",
    "data = data[['text', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset without length column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json('RapNotRap.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether data is similar distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2771.149953574745"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(adv_data['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990.6877696802169"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(adv_data['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2662.064718162839"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(raps['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959.9500546312813"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(raps['n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks good ?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
