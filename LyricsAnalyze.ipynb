{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from progress.bar import PixelBar\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import json\n",
    "import re\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "data = None\n",
    "with open('lyrics.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "if data is not None:\n",
    "    print('Success.')\n",
    "else:\n",
    "    print('Could not read file.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create  Raps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "raps: list = list()\n",
    "for key in data.keys():\n",
    "    if key != 'interrupted':\n",
    "        raps += data[key]\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all non-english texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fmodel = fasttext.load_model('lid.176.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_only = list()\n",
    "for rap in raps:\n",
    "    processed = re.sub(r'\\n', '', rap)\n",
    "    # detect language for each rap\n",
    "    res = fmodel.predict(processed)[0][0]\n",
    "    if res == '__label__en':\n",
    "        en_only.append(rap)\n",
    "raps = en_only\n",
    "del en_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove brackets and respective text inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_brackets: str = r\"\\[([-+&/\\\"'A-Za-z0-9_,\\.;\\s:()Ē?’$éöč!#*–ã“”{}Ž]+)\\]|\\[\\]\"\n",
    "\n",
    "for i, rap in enumerate(raps):\n",
    "    raps[i] = re.sub(regex_brackets, \"\", rap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "escaped = list()\n",
    "for rap in raps:\n",
    "    if bool(re.match(r'\\[(.*)\\]', rap)):\n",
    "        escaped.append(rap)\n",
    "        print(rap)\n",
    "\n",
    "assert len(escaped) == 0, 'Texts not cleaned yet!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove empty lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rap in enumerate(raps):\n",
    "    raps[i] = re.sub(r\"\\n{2,}\", '', rap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load problematic words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "offensive_words: list = []\n",
    "with open('OffWords.txt', 'r') as file:\n",
    "    while (line := file.readline().rstrip()):\n",
    "       offensive_words.append(line.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count often occuring words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe: any = tokenizer.pipe(raps, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "raps_tmp: list = []\n",
    "for i, doc in enumerate(pipe):\n",
    "    if len(doc) < 1000:\n",
    "        raps_tmp.append(raps[i])\n",
    "raps = raps_tmp\n",
    "del raps_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_n: Counter = Counter()\n",
    "word_without_stopwords: Counter = Counter()\n",
    "off_word_n: Counter = Counter()\n",
    "length_arr: np.ndarray = np.array([])\n",
    "\n",
    "bar = PixelBar('Processing', max=len(raps))\n",
    "\n",
    "for doc in pipe:\n",
    "    length_arr = np.append(length_arr, len(doc))\n",
    "    for token in doc:\n",
    "        token_text: str = token.text\n",
    "        if token_text in offensive_words:\n",
    "            off_word_n[token_text] += 1\n",
    "        token_lemma: str = token.lemma_\n",
    "        if token_lemma == '\\n':\n",
    "            continue\n",
    "        if token_lemma.lower() not in stopwords.words('english'):\n",
    "            word_without_stopwords[token_lemma] += 1\n",
    "        word_n[token_lemma] += 1\n",
    "    bar.next()\n",
    "bar.finish()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter2dict: callable = lambda counter: pd.DataFrame.from_dict({'keys': counter.keys(), 'n': counter.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_off: pd.DataFrame = counter2dict(off_word_n)\n",
    "df_off.sort_values(by=['n'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemmas: pd.DataFrame = counter2dict(word_n)\n",
    "df_lemmas.sort_values(by=['n'], ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lemmas_ws: pd.DataFrame = counter2dict(word_without_stopwords)\n",
    "df_lemmas_ws.sort_values(by=['n'], ascending=False).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword-Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_extractor: any = yake.KeywordExtractor()\n",
    "language: str = \"en\"\n",
    "max_ngram_size: int = 3\n",
    "deduplication_threshold: float = 0.9\n",
    "numOfKeywords: int = 15\n",
    "\n",
    "keyword_list: list = []\n",
    "for rap in raps:\n",
    "    custom_kw_extractor = yake.KeywordExtractor(\n",
    "        lan=language,\n",
    "        n=max_ngram_size,\n",
    "        dedupLim=deduplication_threshold,\n",
    "        top=numOfKeywords,\n",
    "        features=None)\n",
    "    keywords = custom_kw_extractor.extract_keywords(rap)\n",
    "    keywords = list(zip(*keywords))\n",
    "    keyword_list.append(', '.join(list(keywords[0])) if len(keywords) > 0 else None)\n",
    "\n",
    "df: pd.DataFrame = pd.DataFrame.from_dict({'keywords': keyword_list, 'lyrics': raps})\n",
    "df = df.dropna()\n",
    "df['text'] = 'KEYWORDS ' + df['keywords'].astype(str) + ' RAP_BEGIN ' + df['lyrics'].astype(str)\n",
    "df[['text']].to_json('KeywordLyrics.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KEYWORDS Dresta done stepped, Gangsta Dresta, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KEYWORDS boy, pull your card, hard, boys, talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KEYWORDS Hey Yella, Nigga, bitch, shit, Ruthle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>KEYWORDS Parental discretion, Ayo Dre, Dre, Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>KEYWORDS picture worth, worth a thousand, thou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>KEYWORDS rap shit, shit, grade, felt fantastic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>KEYWORDS back, Nigga, real, round, back home, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>KEYWORDS bag, Yup, girl, Chino Hills, love, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>KEYWORDS racks, Yeah, racks and things, things...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>KEYWORDS y'all, nigga, shit, bitch named Cryst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4366 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     KEYWORDS Dresta done stepped, Gangsta Dresta, ...\n",
       "1     KEYWORDS boy, pull your card, hard, boys, talk...\n",
       "10    KEYWORDS Hey Yella, Nigga, bitch, shit, Ruthle...\n",
       "100   KEYWORDS Parental discretion, Ayo Dre, Dre, Pa...\n",
       "1000  KEYWORDS picture worth, worth a thousand, thou...\n",
       "...                                                 ...\n",
       "995   KEYWORDS rap shit, shit, grade, felt fantastic...\n",
       "996   KEYWORDS back, Nigga, real, round, back home, ...\n",
       "997   KEYWORDS bag, Yup, girl, Chino Hills, love, lo...\n",
       "998   KEYWORDS racks, Yeah, racks and things, things...\n",
       "999   KEYWORDS y'all, nigga, shit, bitch named Cryst...\n",
       "\n",
       "[4366 rows x 1 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_: pd.DataFrame = pd.read_json('KeywordLyrics.json')\n",
    "df_"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
